{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDU0XJ1xRDlL"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5afkyDMSBW5"
      },
      "source": [
        "## Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "kc4WxYmLSBW5",
        "outputId": "b5b52082-0a87-4190-e136-f7f6d9cf1fc6",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (1.48.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.12.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.0)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.18.0)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.4)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-cloud-aiplatform) (4.25.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.23.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.29.0)\n",
            "Requirement already satisfied: docstring-parser<1 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: pydantic<3 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.7.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.20.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.16.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.31.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.3)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (2.18.1)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.26.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sanskar/git/work/Reply-labcamp/venv/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.2.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip3 install google-cloud-aiplatform pandas scikit-learn seaborn --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ! export GOOGLE_APPLICATION_CREDENTIALS=\"/sa-keys/labcamp-cred.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuQwwRiniVFG"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rtMowvm-yQ97"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../sa-keys/labcamp_cred.json\"\n",
        "vertexai.init(project=\"cgai-project-1\", location=\"us-central1\")\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from IPython.display import Markdown, display\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from vertexai.language_models import (\n",
        "    TextGenerationModel,\n",
        "    TextEmbeddingModel,\n",
        "    ChatModel,\n",
        "    InputOutputTextPair,\n",
        "    CodeGenerationModel,\n",
        "    CodeChatModel,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mU6EZEhakVu"
      },
      "source": [
        "### Text generation with `text-bison@001`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4437b7608c8e"
      },
      "source": [
        "#### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2998506fe6d1"
      },
      "outputs": [],
      "source": [
        "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCgBDJvNRCF5"
      },
      "source": [
        "Create your first prompt and send it to the text generation model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx_o455SRCF5",
        "outputId": "07ea9249-e659-42db-e08e-bb83bf3095b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A large language model (LLM) is a type of artificial intelligence (AI) model that can understand and generate human language. LLMs are trained on massive datasets of text and code, and they can learn to perform a wide variety of tasks, such as translating languages, writing different kinds of creative content, and answering your questions in an informative way.\n",
            "\n",
            "LLMs are still under development, but they have the potential to revolutionize many industries. For example, LLMs could be used to create more accurate and personalized customer service experiences, to help doctors diagnose and treat diseases, and to even write entire books and movies.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What is a large language model?\"\n",
        "\n",
        "response = generation_model.predict(prompt=prompt)\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us8idXnVyQ97"
      },
      "source": [
        "#### Try out your own prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmAZQW1GyQ97",
        "outputId": "2a20a6c5-38ea-4435-9baf-14241a3e20fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. **Artificial intelligence**\n",
            "2. **Machine learning**\n",
            "3. **Blockchain**\n",
            "4. **Virtual reality**\n",
            "5. **Augmented reality**\n",
            "6. **5G**\n",
            "7. **Edge computing**\n",
            "8. **Internet of things**\n",
            "9. **Self-driving cars**\n",
            "10. **Wearables**\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"Create a numbered list of 10 items. Each item in the list should be a trend in the tech industry.\n",
        "\n",
        "Each trend should be less than 5 words.\"\"\"  # try your own prompt\n",
        "\n",
        "response = generation_model.predict(prompt=prompt)\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsglQtgDRCF5"
      },
      "source": [
        "#### Prompt templates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BP1BKWiRCF6"
      },
      "source": [
        "There are many ways to implement prompt templates, and below is just one example using f-strings. (Importing variables into the prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2USfPyOuFhlB",
        "outputId": "bf7e6da7-52bf-4ba0-e1a4-992b326c099b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. **Artificial intelligence**\n",
            "2. **Machine learning**\n",
            "3. **Blockchain**\n",
            "4. **Virtual reality**\n",
            "5. **Augmented reality**\n",
            "6. **5G**\n",
            "7. **Edge computing**\n",
            "8. **Internet of things**\n",
            "9. **Self-driving cars**\n",
            "10. **Wearables**\n"
          ]
        }
      ],
      "source": [
        "my_industry = \"tech\"  # try changing this to a different industry\n",
        "\n",
        "response = generation_model.predict(\n",
        "    prompt=f\"\"\"Create a numbered list of 10 items. Each item in the list should\n",
        "    be a trend in the {my_industry} industry.\n",
        "\n",
        "    Each trend should be less than 5 words.\"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m65AyLt8yvdB"
      },
      "source": [
        "### Model parameters for `text-bison@001`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQuZh6GT0Yn4"
      },
      "source": [
        "You can customize how the PaLM API behaves in response to your prompt by using the following parameters for `text-bison@001`:\n",
        "\n",
        " - `temperature`: higher means more \"creative\" responses\n",
        " - `max_output_tokens`: sets the max number of tokens in the output\n",
        " - `top_p`: higher means it will pull from more possible next tokens, based on cumulative probability\n",
        " - `top_k`: higher means it will sample from more possible next tokens\n",
        "\n",
        "The section below covers each parameter and how to use them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMEz2P18SBW-"
      },
      "source": [
        "Testing that with `temperature=0`, the result is deterministic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxPM1A8uR81l",
        "outputId": "abdad04d-f6c4-4ebd-b34c-f3db713693e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[temperature = 0.0]\n",
            "As I prepared the picture frame, I reached into my toolkit to fetch my hammer.\n"
          ]
        }
      ],
      "source": [
        "temp_val = 0.0\n",
        "prompt_temperature = \"Complete the sentence: As I prepared the picture frame, I reached into my toolkit to fetch my:\"\n",
        "\n",
        "response = generation_model.predict(\n",
        "    prompt=prompt_temperature,\n",
        "    temperature=temp_val,\n",
        ")\n",
        "\n",
        "print(f\"[temperature = {temp_val}]\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B91rIFiSBW_"
      },
      "source": [
        "Increase the temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2mKiDB5SBW_",
        "outputId": "553ad25e-2497-4d9b-8fc5-faae7e465da0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[temperature = 1.0]\n",
            "As I prepared the picture frame, I reached into my toolkit to fetch my tape measure.\n"
          ]
        }
      ],
      "source": [
        "temp_val = 1.0\n",
        "\n",
        "response = generation_model.predict(\n",
        "    prompt=prompt_temperature,\n",
        "    temperature=temp_val,\n",
        ")\n",
        "\n",
        "print(f\"[temperature = {temp_val}]\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRYTOKQpGpfP"
      },
      "source": [
        "##### What is _max_output_tokens_?\n",
        "`max_output_tokens` is the maximum number of tokens that can be generated in the response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUjANX_mNLuI",
        "outputId": "b57018fc-3435-4107-9323-b286327948f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[max_output_tokens = 5]\n",
            "1. **Personal\n"
          ]
        }
      ],
      "source": [
        "max_output_tokens_val = 5\n",
        "\n",
        "response = generation_model.predict(\n",
        "    prompt=\"List ten ways that generative AI can help improve the online shopping experience for users\",\n",
        "    max_output_tokens=max_output_tokens_val,\n",
        ")\n",
        "\n",
        "print(f\"[max_output_tokens = {max_output_tokens_val}]\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DiHeUgSNX1m",
        "outputId": "51ff4068-26f7-4400-b561-228361e6f7be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[max_output_tokens = 500]\n",
            "1. **Personalized recommendations.** Generative AI can be used to create personalized recommendations for users based on their past purchases, browsing history, and other factors. This can help users find products that they are interested in and that are likely to be a good fit for them.\n",
            "2. **Virtual try-on.** Generative AI can be used to create virtual try-on experiences for users, allowing them to see how different products would look on them before they buy them. This can help users make more informed decisions about their purchases and reduce the risk of buyer's remorse.\n",
            "3. **Product design.** Generative AI can be used to help designers create new products that are more innovative and appealing to consumers. This can help businesses stay ahead of the competition and bring new products to market faster.\n",
            "4. **Pricing.** Generative AI can be used to help businesses set prices for their products. This can help businesses maximize their profits and ensure that they are not overcharging or undercharging for their products.\n",
            "5. **Marketing.** Generative AI can be used to create marketing campaigns that are more effective and targeted. This can help businesses reach a wider audience and generate more leads.\n",
            "6. **Customer service.** Generative AI can be used to provide customer service in a more efficient and personalized way. This can help businesses resolve customer issues faster and improve customer satisfaction.\n",
            "7. **Fraud detection.** Generative AI can be used to detect fraud in online transactions. This can help businesses protect themselves from financial loss and ensure that their customers are safe.\n",
            "8. **Inventory management.** Generative AI can be used to help businesses manage their inventory more effectively. This can help businesses avoid stockouts and ensure that they have the right products in stock when customers need them.\n",
            "9. **Supply chain management.** Generative AI can be used to help businesses manage their supply chains more efficiently. This can help businesses reduce costs and improve delivery times.\n",
            "10. **Logistics.** Generative AI can be used to help businesses optimize their logistics operations. This can help businesses reduce costs and improve the efficiency of their shipping and delivery processes.\n"
          ]
        }
      ],
      "source": [
        "max_output_tokens_val = 500\n",
        "\n",
        "response = generation_model.predict(\n",
        "    prompt=\"List ten ways that generative AI can help improve the online shopping experience for users\",\n",
        "    max_output_tokens=max_output_tokens_val,\n",
        ")\n",
        "\n",
        "print(f\"[max_output_tokens = {max_output_tokens_val}]\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRVHZ546yQ98"
      },
      "source": [
        "For easier reading, you can also render Markdown in Jupyter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "6MxmNsp-yQ98",
        "outputId": "8c95310e-4488-4e79-813b-72fdbd7789c3"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "1. **Personalized recommendations.** Generative AI can be used to create personalized recommendations for users based on their past purchases, browsing history, and other factors. This can help users find products that they are interested in and that are likely to be a good fit for them.\n",
              "2. **Virtual try-on.** Generative AI can be used to create virtual try-on experiences for users, allowing them to see how different products would look on them before they buy them. This can help users make more informed decisions about their purchases and reduce the risk of buyer's remorse.\n",
              "3. **Product design.** Generative AI can be used to help designers create new products that are more innovative and appealing to consumers. This can help businesses stay ahead of the competition and bring new products to market faster.\n",
              "4. **Pricing.** Generative AI can be used to help businesses set prices for their products. This can help businesses maximize their profits and ensure that they are not overcharging or undercharging for their products.\n",
              "5. **Marketing.** Generative AI can be used to create marketing campaigns that are more effective and targeted. This can help businesses reach a wider audience and generate more leads.\n",
              "6. **Customer service.** Generative AI can be used to provide customer service in a more efficient and personalized way. This can help businesses resolve customer issues faster and improve customer satisfaction.\n",
              "7. **Fraud detection.** Generative AI can be used to detect fraud in online transactions. This can help businesses protect themselves from financial loss and ensure that their customers are safe.\n",
              "8. **Inventory management.** Generative AI can be used to help businesses manage their inventory more effectively. This can help businesses avoid stockouts and ensure that they have the right products in stock when customers need them.\n",
              "9. **Supply chain management.** Generative AI can be used to help businesses manage their supply chains more efficiently. This can help businesses reduce costs and improve delivery times.\n",
              "10. **Logistics.** Generative AI can be used to help businesses optimize their logistics operations. This can help businesses reduce costs and improve the efficiency of their shipping and delivery processes."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD3S2XsnHL50"
      },
      "source": [
        "#### The `top_p` parameter (range: 0.0 - 1.0, default 0.95)\n",
        "The `top_p` parameter is used to control the diversity of the generated text. A higher `top_p` parameter value results in more \"diverse\" and \"interesting\" outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAJiVYprNle1",
        "outputId": "0ba0ff58-7a1f-4f8a-8525-4ef82b4a764e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[top_p = 0.0]\n",
            "```\n",
            "Introducing the new Blue Elephant Avocado Jacket! This stylish and sustainable jacket is made from recycled materials and is perfect for any occasion.\n",
            "\n",
            "The Blue Elephant Avocado Jacket is made from a soft, breathable fabric that will keep you warm and comfortable all day long. It features a relaxed fit and a variety of pockets to keep your essentials organized.\n",
            "\n",
            "The Blue Elephant Avocado Jacket is also a fashion statement. The bold blue color and fun avocado print will turn heads wherever you go.\n",
            "\n",
            "But what really sets the Blue Elephant Avocado Jacket apart is its sustainability. This jacket is made from recycled materials, and it is also certified by\n"
          ]
        }
      ],
      "source": [
        "top_p_val = 0.0\n",
        "prompt_top_p_example = (\n",
        "    \"Create a marketing campaign for jackets that involves blue elephants and avocados.\"\n",
        ")\n",
        "\n",
        "response = generation_model.predict(\n",
        "    prompt=prompt_top_p_example, temperature=0.9, top_p=top_p_val\n",
        ")\n",
        "\n",
        "print(f\"[top_p = {top_p_val}]\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zm69kbcyN2gg",
        "outputId": "70a9ff00-ef5e-429b-864a-42660bae8abc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[top_p = 1.0]\n",
            "**Introducing the new line of jackets from Blue Elephant Apparel!**\n",
            "\n",
            "These jackets are made with a soft, durable fabric that will keep you warm and comfortable all winter long. They're also water-resistant, so you can stay dry even in the rain.\n",
            "\n",
            "But what really sets these jackets apart is their unique design. Each jacket is embroidered with a blue elephant and an avocado, making it a stylish statement piece that will turn heads wherever you go.\n",
            "\n",
            "**Order yours today and see the difference!**\n",
            "\n",
            "**Here are some of the benefits of our jackets:**\n",
            "\n",
            "* Made with a soft\n"
          ]
        }
      ],
      "source": [
        "top_p_val = 1.0\n",
        "\n",
        "response = generation_model.predict(\n",
        "    prompt=prompt_top_p_example, temperature=0.9, top_p=top_p_val\n",
        ")\n",
        "\n",
        "print(f\"[top_p = {top_p_val}]\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Krop7HXOIy8f"
      },
      "source": [
        "#### The `top_k` parameter (range: 0.0 - 40, default 40)\n",
        "\n",
        "##### What is _top_k_?\n",
        "A`top_k` of 3 means that the next token is selected from the top 3 most probable tokens (using temperature). For each token selection step, the `top_k` tokens with the highest probabilities are sampled. Then tokens are further filtered based on `top_p` with the final token selected using temperature sampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK76o1hYO3ej",
        "outputId": "f85330f7-021a-4c1b-b84c-2023ab68c3c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[top_k = 1]\n",
            "Day 1:\n",
            "* Morning: Start your day in Paris with a visit to the Eiffel Tower. Take the elevator to the top for stunning views of the city.\n",
            "* Afternoon: After lunch, visit the Louvre Museum, one of the largest and most famous museums in the world. See some of the most iconic works of art, including the Mona Lisa and Venus de Milo.\n",
            "* Evening: Enjoy a romantic dinner at a traditional French restaurant.\n",
            "\n",
            "Day 2:\n",
            "* Morning: Take a day trip to Versailles, the former home of French royalty. Explore the opulent palace and gardens.\n",
            "* Afternoon: Visit the Palace of Fontainebleau, another former royal residence. See the beautiful architecture and gardens.\n",
            "* Evening: Enjoy a leisurely dinner at a restaurant in Montmartre, a charming neighborhood in Paris.\n"
          ]
        }
      ],
      "source": [
        "prompt_top_k_example = \"Write a 2-day itinerary for France.\"\n",
        "top_k_val = 1\n",
        "\n",
        "response = generation_model.predict(\n",
        "    prompt=prompt_top_k_example, max_output_tokens=300, temperature=0.9, top_k=top_k_val\n",
        ")\n",
        "\n",
        "print(f\"[top_k = {top_k_val}]\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhu9d23vPGmK",
        "outputId": "cde1a539-f381-491b-e582-a24ac29f3bc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[top_k = 40]\n",
            "Day 1:\n",
            "* Morning: Start your day with a visit to the Eiffel Tower. Take the elevator to the top for stunning views of Paris.\n",
            "* Afternoon: Visit the Louvre Museum, one of the largest and most famous museums in the world. See works by some of the most famous artists in history, including Leonardo da Vinci, Michelangelo, and Rembrandt.\n",
            "* Evening: Enjoy a romantic dinner at a cozy bistro in Montmartre.\n",
            "\n",
            "Day 2:\n",
            "* Morning: Take a stroll through the Tuileries Gardens, a beautiful park in the heart of Paris.\n",
            "* Afternoon: Visit the Palace of Versailles, a UNESCO World Heritage Site. See the opulent royal apartments and gardens.\n",
            "* Evening: Catch a show at the Moulin Rouge, a world-famous cabaret.\n"
          ]
        }
      ],
      "source": [
        "top_k_val = 40\n",
        "\n",
        "response = generation_model.predict(\n",
        "    prompt=prompt_top_k_example,\n",
        "    max_output_tokens=300,\n",
        "    temperature=0.9,\n",
        "    top_k=top_k_val,\n",
        ")\n",
        "\n",
        "print(f\"[top_k = {top_k_val}]\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14ada40abecc"
      },
      "source": [
        "## Chat model with `chat-bison@001`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1325438b9188",
        "outputId": "517f751e-73cf-4882-d590-a269b6a76b94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultiCandidateTextGenerationResponse(text=\"Artificial intelligence (AI) is a branch of computer science that deals with the creation of intelligent agents, which are systems that can reason, learn, and act autonomously. AI has the potential to revolutionize many aspects of our lives, from the way we work and play to the way we interact with the world around us.\\n\\nThe impact of AI on society is a complex and multifaceted issue. On the one hand, AI has the potential to solve some of the world's most pressing problems, such as climate change, poverty, and disease. AI can also be used to create new products and services that improve our lives in ways that we can't even imagine.\\n\\nOn the other hand, AI also poses a number of risks to society. AI systems can be used to create autonomous weapons systems that could kill without human intervention. AI can also be used to create surveillance systems that track and monitor our every move.\\n\\nThe future of AI is uncertain. It is possible that AI will be used for good, or it is possible that AI will be used for evil. It is up to us to decide how AI is used, and to ensure that AI is used for the benefit of humanity, not to its detriment.\\n\\nIn this paper, we will explore the potential impact of AI on society. We will discuss the benefits and risks of AI, and we will consider the ways in which AI can be used to solve some of the world's most pressing problems. We will also discuss the challenges that need to be overcome in order to ensure that AI is used for good.\\n\\nWe believe that AI has the potential to make the world a better place. However, we also believe that it is important to be aware of the risks associated with AI. By understanding the potential impact of AI, we can take steps to ensure that AI is used for the benefit of humanity, not to its detriment.\", _prediction_response=Prediction(predictions=[{'candidates': [{'content': \"Artificial intelligence (AI) is a branch of computer science that deals with the creation of intelligent agents, which are systems that can reason, learn, and act autonomously. AI has the potential to revolutionize many aspects of our lives, from the way we work and play to the way we interact with the world around us.\\n\\nThe impact of AI on society is a complex and multifaceted issue. On the one hand, AI has the potential to solve some of the world's most pressing problems, such as climate change, poverty, and disease. AI can also be used to create new products and services that improve our lives in ways that we can't even imagine.\\n\\nOn the other hand, AI also poses a number of risks to society. AI systems can be used to create autonomous weapons systems that could kill without human intervention. AI can also be used to create surveillance systems that track and monitor our every move.\\n\\nThe future of AI is uncertain. It is possible that AI will be used for good, or it is possible that AI will be used for evil. It is up to us to decide how AI is used, and to ensure that AI is used for the benefit of humanity, not to its detriment.\\n\\nIn this paper, we will explore the potential impact of AI on society. We will discuss the benefits and risks of AI, and we will consider the ways in which AI can be used to solve some of the world's most pressing problems. We will also discuss the challenges that need to be overcome in order to ensure that AI is used for good.\\n\\nWe believe that AI has the potential to make the world a better place. However, we also believe that it is important to be aware of the risks associated with AI. By understanding the potential impact of AI, we can take steps to ensure that AI is used for the benefit of humanity, not to its detriment.\", 'author': '1'}], 'groundingMetadata': [{}], 'citationMetadata': [{'citations': [{'startIndex': 0.0, 'url': 'https://www.thebookcoach.co/post/how-to-use-ai-to-brainstorm-a-novel-s-plot', 'endIndex': 177.0}, {'startIndex': 77.0, 'url': 'https://www.trimatrik.com.bd/product-category/attendance-access-control/face-reader-ta-ac/', 'endIndex': 217.0}]}], 'safetyAttributes': [{'blocked': False, 'safetyRatings': [{'probabilityScore': 0.2, 'severityScore': 0.0, 'severity': 'NEGLIGIBLE', 'category': 'Dangerous Content'}, {'probabilityScore': 0.1, 'severityScore': 0.0, 'severity': 'NEGLIGIBLE', 'category': 'Harassment'}, {'probabilityScore': 0.0, 'severityScore': 0.0, 'severity': 'NEGLIGIBLE', 'category': 'Hate Speech'}, {'probabilityScore': 0.1, 'severityScore': 0.0, 'severity': 'NEGLIGIBLE', 'category': 'Sexually Explicit'}], 'scores': [0.9, 0.5, 0.1, 0.1, 0.1], 'categories': ['Finance', 'Health', 'Insult', 'Profanity', 'Sexual']}]}], deployed_model_id='', metadata={'tokenMetadata': {'inputTokenCount': {'totalTokens': 31.0, 'totalBillableCharacters': 90.0}, 'outputTokenCount': {'totalTokens': 385.0, 'totalBillableCharacters': 1441.0}}}, model_version_id='', model_resource_name='', explanations=None), is_blocked=False, errors=(), safety_attributes={'Finance': 0.9, 'Health': 0.5, 'Insult': 0.1, 'Profanity': 0.1, 'Sexual': 0.1}, grounding_metadata=GroundingMetadata(citations=[], search_queries=[]), candidates=[Artificial intelligence (AI) is a branch of computer science that deals with the creation of intelligent agents, which are systems that can reason, learn, and act autonomously. AI has the potential to revolutionize many aspects of our lives, from the way we work and play to the way we interact with the world around us.\n",
            "\n",
            "The impact of AI on society is a complex and multifaceted issue. On the one hand, AI has the potential to solve some of the world's most pressing problems, such as climate change, poverty, and disease. AI can also be used to create new products and services that improve our lives in ways that we can't even imagine.\n",
            "\n",
            "On the other hand, AI also poses a number of risks to society. AI systems can be used to create autonomous weapons systems that could kill without human intervention. AI can also be used to create surveillance systems that track and monitor our every move.\n",
            "\n",
            "The future of AI is uncertain. It is possible that AI will be used for good, or it is possible that AI will be used for evil. It is up to us to decide how AI is used, and to ensure that AI is used for the benefit of humanity, not to its detriment.\n",
            "\n",
            "In this paper, we will explore the potential impact of AI on society. We will discuss the benefits and risks of AI, and we will consider the ways in which AI can be used to solve some of the world's most pressing problems. We will also discuss the challenges that need to be overcome in order to ensure that AI is used for good.\n",
            "\n",
            "We believe that AI has the potential to make the world a better place. However, we also believe that it is important to be aware of the risks associated with AI. By understanding the potential impact of AI, we can take steps to ensure that AI is used for the benefit of humanity, not to its detriment.])\n"
          ]
        }
      ],
      "source": [
        "chat_model = ChatModel.from_pretrained(\"chat-bison@001\")\n",
        "\n",
        "chat = chat_model.start_chat()\n",
        "\n",
        "print(\n",
        "    chat.send_message(\n",
        "        \"\"\"\n",
        "Hello! Can you write a 300 word abstract for a research paper I need to write about the impact of AI on society?\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef81f564bed1"
      },
      "source": [
        "As shown below, the model should respond based on what was previously said in the conversation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30ab5afac7dc",
        "outputId": "47f68b90-4177-403b-e862-4ecebaba0bfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultiCandidateTextGenerationResponse(text='The Impact of Artificial Intelligence on Society', _prediction_response=Prediction(predictions=[{'candidates': [{'content': 'The Impact of Artificial Intelligence on Society', 'author': 'bot'}], 'groundingMetadata': [{}], 'citationMetadata': [{'citations': []}], 'safetyAttributes': [{'blocked': False, 'safetyRatings': [{'probabilityScore': 0.1, 'severityScore': 0.1, 'severity': 'NEGLIGIBLE', 'category': 'Dangerous Content'}, {'probabilityScore': 0.2, 'severityScore': 0.1, 'severity': 'NEGLIGIBLE', 'category': 'Harassment'}, {'probabilityScore': 0.1, 'severityScore': 0.1, 'severity': 'NEGLIGIBLE', 'category': 'Hate Speech'}, {'probabilityScore': 0.1, 'severityScore': 0.0, 'severity': 'NEGLIGIBLE', 'category': 'Sexually Explicit'}], 'scores': [0.1, 0.1, 0.3, 0.2, 0.1], 'categories': ['Derogatory', 'Finance', 'Health', 'Insult', 'Sexual']}]}], deployed_model_id='', metadata={'tokenMetadata': {'inputTokenCount': {'totalTokens': 430.0, 'totalBillableCharacters': 1569.0}, 'outputTokenCount': {'totalTokens': 7.0, 'totalBillableCharacters': 42.0}}}, model_version_id='', model_resource_name='', explanations=None), is_blocked=False, errors=(), safety_attributes={'Derogatory': 0.1, 'Finance': 0.1, 'Health': 0.3, 'Insult': 0.2, 'Sexual': 0.1}, grounding_metadata=GroundingMetadata(citations=[], search_queries=[]), candidates=[The Impact of Artificial Intelligence on Society])\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    chat.send_message(\n",
        "        \"\"\"\n",
        "Could you give me a catchy title for the paper?\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe15a6b083e5"
      },
      "source": [
        "### Advanced Chat model with the SDK\n",
        "You can also provide a `context` and `examples` to the model. The model will then respond based on the provided context and examples. You can also use `temperature`, `max_output_tokens`, `top_p`, and `top_k`. These parameters should be used when you start your chat with `chat_model.start_chat()`.\n",
        "\n",
        "For more information on chat models, please refer to the [documentation on chat model parameters](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models#chat_model_parameters)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4047b525961e",
        "outputId": "ba5257f8-660b-46dd-8ff0-0e3bab99e910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultiCandidateTextGenerationResponse(text='Yes, they are.', _prediction_response=Prediction(predictions=[{'candidates': [{'content': 'Yes, they are.', 'author': '1'}], 'groundingMetadata': [{}], 'citationMetadata': [{'citations': []}], 'safetyAttributes': [{'blocked': False, 'safetyRatings': [{'probabilityScore': 0.0, 'severityScore': 0.0, 'severity': 'NEGLIGIBLE', 'category': 'Dangerous Content'}, {'probabilityScore': 0.1, 'severityScore': 0.0, 'severity': 'NEGLIGIBLE', 'category': 'Harassment'}, {'probabilityScore': 0.1, 'severityScore': 0.1, 'severity': 'NEGLIGIBLE', 'category': 'Hate Speech'}, {'probabilityScore': 0.1, 'severityScore': 0.1, 'severity': 'NEGLIGIBLE', 'category': 'Sexually Explicit'}], 'scores': [0.1, 0.1, 0.1, 0.1], 'categories': ['Derogatory', 'Finance', 'Insult', 'Sexual']}]}], deployed_model_id='', metadata={'tokenMetadata': {'outputTokenCount': {'totalTokens': 5.0, 'totalBillableCharacters': 12.0}, 'inputTokenCount': {'totalTokens': 54.0, 'totalBillableCharacters': 182.0}}}, model_version_id='', model_resource_name='', explanations=None), is_blocked=False, errors=(), safety_attributes={'Derogatory': 0.1, 'Finance': 0.1, 'Insult': 0.1, 'Sexual': 0.1}, grounding_metadata=GroundingMetadata(citations=[], search_queries=[]), candidates=[Yes, they are.])\n"
          ]
        }
      ],
      "source": [
        "chat = chat_model.start_chat(\n",
        "    context=\"My name is Ned. You are my personal assistant. My favorite movies are Lord of the Rings and Hobbit.\",\n",
        "    examples=[\n",
        "        InputOutputTextPair(\n",
        "            input_text=\"Who do you work for?\",\n",
        "            output_text=\"I work for Ned.\",\n",
        "        ),\n",
        "        InputOutputTextPair(\n",
        "            input_text=\"What do I like?\",\n",
        "            output_text=\"Ned likes watching movies.\",\n",
        "        ),\n",
        "    ],\n",
        "    temperature=0.3,\n",
        "    max_output_tokens=200,\n",
        "    top_p=0.8,\n",
        "    top_k=40,\n",
        ")\n",
        "print(chat.send_message(\"Are my favorite movies based on a book series?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "685184ee4159",
        "outputId": "72975094-4c80-42bc-9b23-5642531fe06f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultiCandidateTextGenerationResponse(text='The Lord of the Rings was published in 1954 and The Hobbit was published in 1937.', _prediction_response=Prediction(predictions=[{'candidates': [{'content': 'The Lord of the Rings was published in 1954 and The Hobbit was published in 1937.', 'author': 'bot'}], 'groundingMetadata': [{}], 'citationMetadata': [{'citations': []}], 'safetyAttributes': [{'blocked': False, 'safetyRatings': [{'probabilityScore': 0.1, 'severityScore': 0.0, 'severity': 'NEGLIGIBLE', 'category': 'Dangerous Content'}, {'probabilityScore': 0.1, 'severityScore': 0.0, 'severity': 'NEGLIGIBLE', 'category': 'Harassment'}, {'probabilityScore': 0.1, 'severityScore': 0.1, 'severity': 'NEGLIGIBLE', 'category': 'Hate Speech'}, {'probabilityScore': 0.2, 'severityScore': 0.0, 'severity': 'NEGLIGIBLE', 'category': 'Sexually Explicit'}], 'scores': [0.1, 0.1, 0.1, 0.2], 'categories': ['Derogatory', 'Insult', 'Religion & Belief', 'Sexual']}]}], deployed_model_id='', metadata={'tokenMetadata': {'inputTokenCount': {'totalTokens': 65.0, 'totalBillableCharacters': 223.0}, 'outputTokenCount': {'totalTokens': 25.0, 'totalBillableCharacters': 66.0}}}, model_version_id='', model_resource_name='', explanations=None), is_blocked=False, errors=(), safety_attributes={'Derogatory': 0.1, 'Insult': 0.1, 'Religion & Belief': 0.1, 'Sexual': 0.2}, grounding_metadata=GroundingMetadata(citations=[], search_queries=[]), candidates=[The Lord of the Rings was published in 1954 and The Hobbit was published in 1937.])\n"
          ]
        }
      ],
      "source": [
        "print(chat.send_message(\"When where these books published?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67b6eef99f56"
      },
      "source": [
        "## Embedding model with `textembedding-gecko@001`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0f175d5b02a",
        "outputId": "e858efb6-5e36-4b36-fa3c-bccd49333f9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length = 768\n",
            "[0.010562753304839134, 0.04915031045675278, -0.022224493324756622, 0.0208794716745615, 0.024389723315835, 0.010366306640207767, 0.023919280618429184, 0.022391626611351967, -0.031569067388772964, 0.023535897955298424, -0.017047161236405373, -0.014345862902700901, 0.044956106692552567, 0.027327297255396843, -0.03314697742462158, -0.028214626014232635, -0.035373710095882416, -0.05229683220386505, 0.017105583101511, -0.03780610114336014, -0.07891207933425903, -0.01173518318682909, -0.01629730500280857, -0.04353305324912071, 0.013023999519646168, -0.10904901474714279, -0.0341256819665432, -0.0025329082272946835, -0.036971937865018845, -0.027775181457400322, 0.02332289144396782, 0.0052000475116074085, 0.005503748077899218, 0.0047489493153989315, -0.029920609667897224, 0.07563772797584534, 0.0007565636187791824, 0.03501711040735245, 0.02154686115682125, -0.000812096637673676, 0.06169590726494789, -0.024313345551490784, 0.03736764192581177, -0.0005869767046533525, -0.022872457280755043, -0.0027376075740903616, -0.020049992948770523, 0.015618567354977131, -0.038495443761348724, -0.0029529621824622154, 0.006082594394683838, 0.009469639509916306, -0.01644207164645195, 0.06665747612714767, -0.005011357367038727, 0.02688094601035118, -0.035699062049388885, 0.00722217233851552, -0.02506454475224018, -0.004168056882917881, -0.04915543273091316, 0.017482219263911247, -0.030127059668302536, -0.07361055165529251, -0.02319231443107128, 0.017089763656258583, 0.03889910876750946, 0.004971345886588097, -0.007473395671695471, -0.02317200042307377, 0.027803964912891388, 0.04244052618741989, 0.05573302507400513, 0.030758505687117577, 0.009500554762780666, 0.016260754317045212, -0.010920681059360504, 0.051093071699142456, 0.014400376006960869, -0.04737357795238495, -0.021630441769957542, -0.09906578063964844, -0.04526016488671303, -0.09384721517562866, 0.0203617624938488, -0.010920662432909012, -0.020609041675925255, -0.003635745495557785, 0.010114741511642933, 0.053623370826244354, -0.06474005430936813, 0.016096388921141624, -0.025225313380360603, -0.0019267624011263251, -0.01067234668880701, 0.007826746441423893, 0.013295858167111874, -0.03250099718570709, -0.0005353756714612246, -0.016680261120200157, 0.030173059552907944, -0.046101104468107224, 0.011562732979655266, -0.025579039007425308, 0.04599408432841301, 0.07000190019607544, 0.0018490661168470979, 0.006918175611644983, -0.0686691403388977, -0.06974631547927856, -0.03236835077404976, -0.026718594133853912, 0.0019408509833738208, 0.05204402655363083, 0.04074086248874664, -0.031760964542627335, 0.00344477710314095, -0.026170318946242332, 0.03783925995230675, 0.06050663813948631, -0.01712394505739212, -0.0016355578554794192, 0.013527915813028812, 0.016787230968475342, 0.043276093900203705, -0.016072751954197884, 0.0005571756628341973, -0.013367726467549801, -0.04776871204376221, 0.001129272161051631, 0.05411853268742561, -0.013886460103094578, 0.041834332048892975, -0.04144100472331047, -0.03237384930253029, 0.043086014688014984, -0.027675528079271317, -0.044598691165447235, -0.00594487925991416, 0.06224711984395981, -0.04892174154520035, 0.03044838272035122, 0.03531208634376526, 0.01580674946308136, -0.0012970577226951718, -0.03943518176674843, 0.025564445182681084, -0.03516595438122749, -0.07641597092151642, -0.021444709971547127, 0.020934447646141052, -0.04114843159914017, 0.028761522844433784, 0.03969430550932884, 0.01649416796863079, 0.03781518712639809, 0.005376121494919062, 0.052569981664419174, -0.02991773933172226, -0.043924685567617416, 0.04530343785881996, 2.5027560695889406e-05, -0.03769891336560249, 0.029070040211081505, -0.0015343234408646822, -0.008552037179470062, -0.007152904290705919, 0.08237303048372269, -0.012235905043780804, 0.01122607383877039, 0.025165848433971405, -0.08328612893819809, 0.011945217847824097, 0.0015939214499667287, 0.08520401269197464, -0.021776320412755013, -0.03578481823205948, 0.026176629588007927, 0.01096740085631609, 0.004734116140753031, -0.020438600331544876, -0.04446989297866821, -0.0040295482613146305, 0.023052716627717018, -0.036880459636449814, 0.03397374972701073, -0.04031934216618538, -0.04730498790740967, -0.0050745015032589436, 0.08679068833589554, -0.025848431512713432, -0.019488884136080742, 0.017754653468728065, -0.017796259373426437, -0.023471161723136902, -0.018227828666567802, 0.04445705562829971, -0.10037199407815933, -0.02118160016834736, 0.06375161558389664, -0.008057363331317902, 0.010159569792449474, 0.0227991733700037, 0.020613307133316994, 0.006186176091432571, 0.021146763116121292, -0.05968202278017998, 0.040926363319158554, -0.022863982245326042, -0.03495022654533386, 0.01183225680142641, 0.01046161912381649, 0.005481143016368151, 0.011371520347893238, 0.014836390502750874, -0.034276075661182404, -0.002988190623000264, 0.025690797716379166, -0.05883420631289482, -0.0330558717250824, -0.00978460256010294, 0.04343593493103981, -0.008818176575005054, 0.06544901430606842, 0.04110537841916084, 0.029538320377469063, 0.07326919585466385, -0.011241015046834946, 0.025485657155513763, -0.010350838303565979, -0.03211556375026703, -0.015925990417599678, 0.000886544119566679, 0.0046063438057899475, 0.012922320514917374, 0.04025505855679512, 0.012885822914540768, -0.012207417748868465, -0.004735307767987251, 0.010060984641313553, -0.027444403618574142, 0.05696522817015648, -0.018892325460910797, 0.06066060811281204, -0.013454179279506207, 0.06614361703395844, -0.0624060221016407, 0.027977008372545242, 0.004387756809592247, 0.028211001306772232, 0.014558867551386356, -0.10379569977521896, 0.0005272417911328375, 0.0014677881263196468, 0.023768983781337738, -0.008190426975488663, 0.014077108353376389, 0.013787458650767803, -0.0023947367444634438, 0.0023685458581894636, 0.03789709135890007, 0.012706364504992962, 0.0037047751247882843, 0.09113603085279465, -0.04635924845933914, -0.022722741588950157, -0.0071150148287415504, 0.007771676871925592, 0.01942666433751583, -0.013135110959410667, 0.028210168704390526, 0.010826485231518745, 0.07257974147796631, 0.0733613669872284, -0.0006541117909364402, -0.012512844055891037, -0.039276015013456345, 0.02811293676495552, 0.023050831630825996, 0.02523820474743843, 0.04957246035337448, -0.03153982013463974, 0.007981367409229279, 0.0361814871430397, -0.025585805997252464, 0.027978206053376198, -0.00865026842802763, -0.0331689678132534, -0.09472481161355972, -0.028743796050548553, 0.012484352104365826, 0.0021317009814083576, -0.03636407107114792, 0.06142040714621544, 0.027773819863796234, -0.025848736986517906, 0.051048390567302704, -0.03207724913954735, -0.011837080121040344, 0.003502538427710533, 0.007440628949552774, 0.04633283242583275, -0.021616097539663315, -0.03967327997088432, -0.02479877881705761, -0.061190344393253326, -0.015260206535458565, -0.0352751798927784, 0.021882355213165283, 0.015894176438450813, 0.0028269870672374964, 0.00022079204791225493, -0.013698175549507141, 0.014123217202723026, -0.036067694425582886, 0.011920701712369919, 0.022252820432186127, 0.005743535701185465, -0.0640563890337944, 0.04698688164353371, -0.06404423713684082, -0.013042834587395191, 0.10771365463733673, 0.0010355111444368958, 0.040467679500579834, -0.013715598732233047, -0.009016689844429493, 0.008000747300684452, 0.10234715789556503, -0.07225427031517029, 0.008915708400309086, 0.006237425375729799, -0.021482102572917938, 0.02397948130965233, 0.05135175958275795, 0.015608500689268112, -0.031944625079631805, 0.0382135808467865, 0.005797197110950947, -0.05154971405863762, 0.028097666800022125, -0.02745014801621437, -0.05843295902013779, -0.00718856742605567, 0.004217328503727913, 0.026621710509061813, -0.06410615146160126, -0.027771446853876114, -0.03622982278466225, -0.06002693250775337, 0.0028730896301567554, 0.0009376482921652496, -0.02914406545460224, 0.08022568374872208, -0.028879303485155106, 0.026666102930903435, -0.006004952359944582, 0.001789418631233275, 0.017556296661496162, 0.030322201550006866, -0.029420388862490654, 0.018269363790750504, -0.05464306101202965, 0.025800133123993874, -0.010673671960830688, 0.050776343792676926, -0.09446800500154495, 0.0315055325627327, 0.03829166665673256, -0.035387031733989716, 0.013971587643027306, 0.012318527325987816, -0.015703145414590836, -0.056523360311985016, -0.09211713820695877, 0.011791898868978024, 0.02190352976322174, 0.045681215822696686, 0.025594133883714676, -0.02231750264763832, -0.0066884052939713, -0.0058244881220161915, 0.02482292428612709, -0.025856031104922295, 0.0021307426504790783, 0.007752955891191959, 0.04843730479478836, 0.046476081013679504, -0.008397646248340607, -0.05962646007537842, -0.009551334194839, 0.011616517789661884, 0.02129344455897808, 0.01660742610692978, -0.015061271376907825, 0.10817286372184753, -0.022453995421528816, -0.003983873873949051, -0.05261503532528877, -0.022377099841833115, 0.044437944889068604, 0.020710069686174393, 0.013700924813747406, -0.03116024099290371, -0.008501379750669003, -0.008547067642211914, 0.010543258860707283, 0.05530229210853577, -0.020880352705717087, -0.056557077914476395, -0.00045299093471840024, -0.00036045885644853115, 0.016418904066085815, 0.02558765560388565, -0.006075927522033453, -0.027869651094079018, -0.016028350219130516, -0.024012824520468712, 0.01018358115106821, 0.03202531114220619, 0.007241277489811182, -0.007335623726248741, 0.013699401170015335, 0.021170441061258316, 0.02232292853295803, 0.014576029032468796, -0.09291727840900421, 0.060506802052259445, -0.055237799882888794, -0.03457856923341751, -0.0277749914675951, -0.044067513197660446, -0.03341272100806236, -0.011979644186794758, -0.025669127702713013, -0.02267066389322281, 0.09566973894834518, 0.0767752006649971, 0.010824593715369701, 0.006929770577698946, -0.03011220321059227, -0.0027981619350612164, -0.0684315413236618, -0.005837030243128538, 0.03316957876086235, -0.04451394081115723, 0.0027066227048635483, -0.05395593121647835, -0.04560602083802223, 0.006837170105427504, 0.02234707772731781, -0.034541644155979156, 0.011009179055690765, 0.11418948322534561, -0.0011041957186535, -0.012423255480825901, -0.0037464227061718702, -0.035839445888996124, 0.0022794732358306646, -0.02418961189687252, -0.015126262791454792, -0.041080981492996216, -0.03646824136376381, 0.007073802407830954, -0.008472681045532227, -0.007056590635329485, 0.06429030746221542, 0.020093614235520363, -0.022911274805665016, 0.025473780930042267, 0.007346852216869593, 0.04328314587473869, -0.050240155309438705, 0.014898708090186119, 0.025633497163653374, 0.06909260898828506, 0.03641815483570099, 0.055241573601961136, 0.021067028865218163, 0.007827181369066238, -0.06469225883483887, -0.05607031285762787, 0.010224307887256145, -0.0395328514277935, -0.017940493300557137, -0.025376077741384506, 0.015028695575892925, -0.012133865617215633, -0.05708197131752968, 0.017396116629242897, 0.010713928379118443, 0.0025007263757288456, 0.013599053025245667, 0.01869947463274002, 0.007097666617482901, -0.017439134418964386, 0.032095298171043396, 0.03800633177161217, 0.003494472708553076, 0.046149060130119324, 0.016314545646309853, -0.0063019716180861, 0.026373308151960373, 0.003648587968200445, -0.03535480052232742, 0.021219566464424133, 0.00536026805639267, -0.06234264746308327, -0.05119526386260986, 0.05295814573764801, -0.052322618663311005, 0.04355868324637413, 0.03884781897068024, -0.04070327803492546, -0.05103592202067375, -0.06048445403575897, 0.022206993773579597, -0.0005872139008715749, 0.009120561182498932, 0.04792363569140434, -0.02097858302295208, -0.04793033376336098, -0.020198754966259003, 0.033280182629823685, 0.0031431131064891815, 0.06413375586271286, 0.005882553290575743, -0.007480444386601448, -0.03405573219060898, 0.04223233088850975, -0.03249271214008331, -0.03100714646279812, 0.0462421253323555, 0.011582289822399616, 0.008000263944268227, -0.010868484154343605, 0.046212539076805115, 0.02901630662381649, 0.005261174403131008, 0.06834172457456589, 0.01993578113615513, -0.06909119337797165, -0.01722937822341919, -0.0073282006196677685, -0.045459046959877014, -0.0057713184505701065, 0.03357113525271416, 0.0037865471094846725, 0.0036972742527723312, 0.005904142279177904, 0.05643080919981003, -0.01644083298742771, -0.040261246263980865, 0.09400543570518494, 4.431899469636846e-06, -0.0490410141646862, 0.03803042694926262, -0.013964969664812088, -0.04580939933657646, -0.04047616571187973, -9.045763727044687e-05, 0.023141689598560333, -0.014303075149655342, -0.02298162318766117, 0.014015794731676579, -0.057407837361097336, 0.06846775859594345, 0.024667343124747276, -0.006628675851970911, 0.06792213767766953, -0.048522815108299255, -0.013445757329463959, -0.016858110204339027, 0.0062940688803792, 0.035504620522260666, 0.032475560903549194, -0.03314086049795151, -0.03431634604930878, -0.019594095647335052, 0.0194022748619318, -0.027126198634505272, -0.026301225647330284, 0.012841426767408848, 0.04247117415070534, -0.0008294038707390428, -0.004414733964949846, -0.013424563221633434, -0.05057736486196518, -0.015919560566544533, -0.02437496744096279, 0.02126476541161537, -0.052758101373910904, -0.00254595885053277, -0.015874166041612625, -0.01196883711963892, -0.030309129506349564, 0.010183988139033318, 0.03598339855670929, 0.022882329300045967, -0.0026234013494104147, 0.01329271774739027, 0.03793490678071976, 0.040360793471336365, 0.009328302927315235, 0.023761970922350883, -0.008133891969919205, 0.003272354369983077, 0.017534887418150902, -0.02026401087641716, 0.04495016857981682, 0.06324293464422226, 0.035437922924757004, 0.022442534565925598, -0.016285236924886703, -0.026689207181334496, -0.02127818949520588, -0.037313684821128845, 0.01911837048828602, 0.025560466572642326, 0.016064390540122986, 0.07720045000314713, -0.009457273408770561, 0.015530860982835293, -0.06052880361676216, -0.022617602720856667, 0.029684558510780334, 0.013369569554924965, 0.022447090595960617, -0.03480006381869316, -0.02661510556936264, 0.011014388874173164, 4.9809288611868396e-05, -0.035971399396657944, -0.04662683233618736, 0.024060387164354324, 0.0023163501173257828, -0.028293997049331665, 0.02313932031393051, 0.011891087517142296, 0.030368415638804436, 0.04482187330722809, 0.022134285420179367, -0.013178267516195774, -0.033628739416599274, 0.0025850499514490366, -0.03433449566364288, -0.027540232986211777, -0.03729564696550369, 0.009291116148233414, 0.0032681135926395655, -0.013214519247412682, -0.019297223538160324, -0.05181577801704407, -0.07788670808076859, 0.005753953009843826, -0.002431269269436598, -0.006063435226678848, 0.056346580386161804, -0.0777992382645607, 0.026173142716288567, 0.039567336440086365, 0.0007441218476742506, 0.005875684786587954, 0.05997183546423912, -0.06708808243274689, 0.007471994962543249, -0.02053227461874485, 0.007481405511498451, 0.041810907423496246, 0.02568086050450802, -0.006198380142450333, -0.05383675917983055, 0.04175911843776703, -0.005462720058858395, -0.05053558945655823, 0.023038415238261223, -0.014262375421822071, 0.007531439885497093, 0.013355238363146782, -0.015866558998823166, -0.07595427334308624, 0.030540091916918755, -0.0801253542304039, -0.023217307403683662, 0.01443509291857481, -0.004276867024600506, 0.05812528729438782, -0.012534553185105324, -0.025629539042711258, -0.01611189916729927, -0.04192844033241272, 0.008887489326298237, -0.018155395984649658, -0.02993370033800602, -0.024211617186665535, -0.015328830108046532, -0.041393671184778214, 0.032823413610458374, -0.001385489129461348, 0.05429193004965782, -0.027885785326361656, -0.008479449898004532, 0.0490122027695179, -0.008184432052075863, 0.044856008142232895, -0.03555196151137352, -0.07294470816850662, -0.07674667239189148, -0.043681032955646515, -0.041639089584350586, -0.02157670259475708, 0.02400614693760872, 0.024259423837065697, 0.031012538820505142, -0.006325466092675924, 0.04981034994125366, -0.014001739211380482, 0.047177840024232864, 0.011161163449287415, -0.009339496493339539, -0.03161853179335594, 0.025517631322145462, 0.02807212620973587, -9.692920866655186e-05, -0.061530858278274536, -0.02346394583582878, 0.020299283787608147, -0.057792555540800095, 0.01165015809237957, 0.017648736014962196, -0.029611079022288322, -0.030652131885290146, 0.0484359934926033, 0.05948704108595848, -0.028600767254829407, 0.0016199287492781878, 0.041371941566467285, 0.021050546318292618, 0.018185807392001152, -0.055236268788576126, -0.028987789526581764, 0.06956813484430313, -0.013538234867155552, -0.014316626824438572, 0.0375431589782238, 0.037525925785303116, 0.012862461619079113, -0.004528065212070942, -0.05409426987171173, -0.027900930494070053, -0.12323915958404541, 0.02516682632267475, 0.013104746118187904, 0.004067264497280121, -0.05458975210785866, 0.05783650279045105, 0.07030092924833298, 0.010288940742611885, -0.02614584006369114, -0.015845855697989464, 0.012834896333515644, 0.009806377813220024, -0.035357676446437836, 0.01626463793218136, 0.002208224032074213, 0.009254978969693184, -0.03647759184241295, -0.05006510391831398]\n"
          ]
        }
      ],
      "source": [
        "embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
        "\n",
        "embeddings = embedding_model.get_embeddings([\"What is life?\"])\n",
        "\n",
        "for embedding in embeddings:\n",
        "    vector = embedding.values\n",
        "    print(f\"Length = {len(vector)}\")\n",
        "    print(vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "601bd7e7ef1d"
      },
      "source": [
        "#### Embeddings and Pandas DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e69d2ba877f"
      },
      "source": [
        "If your text is stored in a column of a DataFrame, you can create a new column with the embeddings with the example below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "d99f08bab254",
        "outputId": "fb505c63-d32f-4470-e540-7ddf6c56f82f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i really enjoyed the movie last night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>so many amazing cinematic scenes yesterday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>had a great time writing my Python scripts a f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>huge sense of relief when my .py script finall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O Romeo, Romeo, wherefore art thou Romeo?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0              i really enjoyed the movie last night\n",
              "1         so many amazing cinematic scenes yesterday\n",
              "2  had a great time writing my Python scripts a f...\n",
              "3  huge sense of relief when my .py script finall...\n",
              "4          O Romeo, Romeo, wherefore art thou Romeo?"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = [\n",
        "    \"i really enjoyed the movie last night\",\n",
        "    \"so many amazing cinematic scenes yesterday\",\n",
        "    \"had a great time writing my Python scripts a few days ago\",\n",
        "    \"huge sense of relief when my .py script finally ran without error\",\n",
        "    \"O Romeo, Romeo, wherefore art thou Romeo?\",\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(text, columns=[\"text\"])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fabd92d8ddb6"
      },
      "source": [
        "Create a new column, `embeddings`, using the [apply](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html) function in pandas with the embeddings model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TV87Dxt8j_BX",
        "outputId": "68323770-c2cd-4be5-8302-437e9d1e58b8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i really enjoyed the movie last night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>so many amazing cinematic scenes yesterday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>had a great time writing my Python scripts a f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>huge sense of relief when my .py script finall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O Romeo, Romeo, wherefore art thou Romeo?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0              i really enjoyed the movie last night\n",
              "1         so many amazing cinematic scenes yesterday\n",
              "2  had a great time writing my Python scripts a f...\n",
              "3  huge sense of relief when my .py script finall...\n",
              "4          O Romeo, Romeo, wherefore art thou Romeo?"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "096cbf3f2698",
        "outputId": "db5cc3c8-5ec9-4c61-82c3-e294204ce6bf",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i really enjoyed the movie last night</td>\n",
              "      <td>[-0.015481960028409958, 0.010654411278665066, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>so many amazing cinematic scenes yesterday</td>\n",
              "      <td>[-0.04475008696317673, 0.03850521519780159, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>had a great time writing my Python scripts a f...</td>\n",
              "      <td>[-0.002235855208709836, -0.009281235747039318,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>huge sense of relief when my .py script finall...</td>\n",
              "      <td>[-0.01665080338716507, 0.009947526268661022, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O Romeo, Romeo, wherefore art thou Romeo?</td>\n",
              "      <td>[0.04232335463166237, -0.02867126651108265, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0              i really enjoyed the movie last night   \n",
              "1         so many amazing cinematic scenes yesterday   \n",
              "2  had a great time writing my Python scripts a f...   \n",
              "3  huge sense of relief when my .py script finall...   \n",
              "4          O Romeo, Romeo, wherefore art thou Romeo?   \n",
              "\n",
              "                                          embeddings  \n",
              "0  [-0.015481960028409958, 0.010654411278665066, ...  \n",
              "1  [-0.04475008696317673, 0.03850521519780159, -0...  \n",
              "2  [-0.002235855208709836, -0.009281235747039318,...  \n",
              "3  [-0.01665080338716507, 0.009947526268661022, 0...  \n",
              "4  [0.04232335463166237, -0.02867126651108265, 0....  "
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"embeddings\"] = df.apply(\n",
        "    lambda x: embedding_model.get_embeddings([x.text])[0].values, axis=1\n",
        ")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69ebe1a6514d"
      },
      "source": [
        "#### Comparing similarity of text examples using cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "dc499dae438a",
        "outputId": "49e0f3e9-fd64-4474-babf-f1954a17201f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>i really enjoyed the movie last night</th>\n",
              "      <th>so many amazing cinematic scenes yesterday</th>\n",
              "      <th>had a great time writing my Python scripts a few days ago</th>\n",
              "      <th>huge sense of relief when my .py script finally ran without error</th>\n",
              "      <th>O Romeo, Romeo, wherefore art thou Romeo?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>i really enjoyed the movie last night</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.719884</td>\n",
              "      <td>0.631067</td>\n",
              "      <td>0.551936</td>\n",
              "      <td>0.459312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>so many amazing cinematic scenes yesterday</th>\n",
              "      <td>0.719884</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.622285</td>\n",
              "      <td>0.564447</td>\n",
              "      <td>0.524029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>had a great time writing my Python scripts a few days ago</th>\n",
              "      <td>0.631067</td>\n",
              "      <td>0.622285</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.738914</td>\n",
              "      <td>0.449386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>huge sense of relief when my .py script finally ran without error</th>\n",
              "      <td>0.551936</td>\n",
              "      <td>0.564447</td>\n",
              "      <td>0.738914</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.435728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O Romeo, Romeo, wherefore art thou Romeo?</th>\n",
              "      <td>0.459312</td>\n",
              "      <td>0.524029</td>\n",
              "      <td>0.449386</td>\n",
              "      <td>0.435728</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    i really enjoyed the movie last night  \\\n",
              "i really enjoyed the movie last night                                            1.000000   \n",
              "so many amazing cinematic scenes yesterday                                       0.719884   \n",
              "had a great time writing my Python scripts a fe...                               0.631067   \n",
              "huge sense of relief when my .py script finally...                               0.551936   \n",
              "O Romeo, Romeo, wherefore art thou Romeo?                                        0.459312   \n",
              "\n",
              "                                                    so many amazing cinematic scenes yesterday  \\\n",
              "i really enjoyed the movie last night                                                 0.719884   \n",
              "so many amazing cinematic scenes yesterday                                            1.000000   \n",
              "had a great time writing my Python scripts a fe...                                    0.622285   \n",
              "huge sense of relief when my .py script finally...                                    0.564447   \n",
              "O Romeo, Romeo, wherefore art thou Romeo?                                             0.524029   \n",
              "\n",
              "                                                    had a great time writing my Python scripts a few days ago  \\\n",
              "i really enjoyed the movie last night                                                        0.631067           \n",
              "so many amazing cinematic scenes yesterday                                                   0.622285           \n",
              "had a great time writing my Python scripts a fe...                                           1.000000           \n",
              "huge sense of relief when my .py script finally...                                           0.738914           \n",
              "O Romeo, Romeo, wherefore art thou Romeo?                                                    0.449386           \n",
              "\n",
              "                                                    huge sense of relief when my .py script finally ran without error  \\\n",
              "i really enjoyed the movie last night                                                        0.551936                   \n",
              "so many amazing cinematic scenes yesterday                                                   0.564447                   \n",
              "had a great time writing my Python scripts a fe...                                           0.738914                   \n",
              "huge sense of relief when my .py script finally...                                           1.000000                   \n",
              "O Romeo, Romeo, wherefore art thou Romeo?                                                    0.435728                   \n",
              "\n",
              "                                                    O Romeo, Romeo, wherefore art thou Romeo?  \n",
              "i really enjoyed the movie last night                                                0.459312  \n",
              "so many amazing cinematic scenes yesterday                                           0.524029  \n",
              "had a great time writing my Python scripts a fe...                                   0.449386  \n",
              "huge sense of relief when my .py script finally...                                   0.435728  \n",
              "O Romeo, Romeo, wherefore art thou Romeo?                                            1.000000  "
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cos_sim_array = cosine_similarity(list(df.embeddings.values))\n",
        "\n",
        "# display as DataFrame\n",
        "df = pd.DataFrame(cos_sim_array, index=text, columns=text)\n",
        "df\n",
        "\n",
        "# The close the result is to 1, the closer the results are"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-11.m108",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
